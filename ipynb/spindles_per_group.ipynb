{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a0da38-ae51-4028-8e3d-515aadbe4ae5",
   "metadata": {},
   "source": [
    "## **Spindle detection**\n",
    "\n",
    "#### Using Yasa Software\n",
    "\n",
    "yasa.spindles_detect\n",
    "\n",
    "yasa.spindles_detect(data, sf=None, ch_names=None, hypno=None, include=1, 2, 3, freq_sp=12, 15, freq_broad=1, 30, duration=0.5, 2, min_distance=500, thresh={'rel_pow': 0.2, 'corr': 0.65, 'rms': 1.5}, multi_only=False, remove_outliers=False, verbose=False)\n",
    "\n",
    "  \n",
    "\n",
    "Single or multi-channel data. Unit must be **uV** and shape (n_samples) or (n_chan, n_samples). Can also be a mne.io.BaseRaw, in which case data, sf, and ch_names will be automatically extracted, and data will also be automatically converted from Volts (MNE) to micro-Volts (YASA).\n",
    "\n",
    "\n",
    "Spindles frequency range. Default is 12 to 15 Hz. Please note that YASA uses a FIR filter (implemented in MNE) with a 1.5Hz transition band, which means that for freq_sp = (12, 15 Hz), the -6 dB points are located at 11.25 and 15.75 Hz.\n",
    "\n",
    "Broad band frequency range. Default is 1 to 30 Hz.\n",
    "\n",
    "\n",
    "The minimum and maximum duration of the spindles. Default is 0.5 to 2 seconds.\n",
    "\n",
    "\n",
    "\n",
    "Detection thresholds:\n",
    "\n",
    "    'rel_pow': Relative power (= power ratio freq_sp / freq_broad).\n",
    "\n",
    "    'corr': Moving correlation between original signal and sigma-filtered signal.\n",
    "\n",
    "    'rms': Number of standard deviations above the mean of a moving root mean square of sigma-filtered signal.\n",
    "\n",
    "You can disable one or more threshold by putting None instead:\n",
    "\n",
    "thresh = {'rel_pow': None, 'corr': 0.65, 'rms': 1.5}\n",
    "thresh = {'rel_pow': None, 'corr': None, 'rms': 3}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813df210-ab27-4eff-9aac-3035ba008a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, 'D:/Beths/')\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yasa\n",
    "import mne\n",
    "from mne.filter import filter_data, resample\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "\n",
    "## Import from my files\n",
    "from data_lfp import mne_lfp_Axona, load_lfp_Axona\n",
    "from data_pos import RecPos\n",
    "from bandPower import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f3593e-e6c4-4c64-a06a-1eda7b4a61a0",
   "metadata": {},
   "source": [
    "#### **Detection of slow-wave sleep, sharp-wave ripples and multi-unit activity bursts**\n",
    "\n",
    "Paper: Coordinated Emergence of Hippocampal Replay and Theta Sequences during Post-natal Development: \n",
    "[https://www.sciencedirect.com/science/article/pii/S0960982219300065]\n",
    "\n",
    "The brain states slow-wave sleep (SWS), rapid-eye movement sleep (REM) and awake movement were defined following [22\n",
    "]. A multitaper power spectral density estimate of the hippocampal local field potential (LFP) was derived for **1.6 s windows** , overlapping by 0.8 s (MATLAB function ‘pmtm’). From this, power in the delta and theta bands were calculated in each window. As theta frequency changes during development [18\n",
    "], theta and delta peak frequencies were calculated for each session, defined as the peak frequency of the fast Fourier transform of the LFP, in the bands 5-11Hz (theta) and 1.5-4Hz (delta). **Mean running speed for each 1.6 s bin was also estimated. In the absence of EMG recordings, we could not unequivocally discriminate between slow wave sleep and quiet immmobility, we therefore restricted all analyses to epochs termed ‘rest’.**\n",
    "\n",
    "Rest was defined as epochs with running speed < 2.5cm/s , and theta/delta power ratio < 2 and waking movement as theta/delta power ratio > 2 and speed > 2.5cm/s. \n",
    "Sharp-wave ripples were detected by first filtering the LFP in the band 100-250Hz. \n",
    "The instantaneous power of the filtered LFP was then estimated by calculating the root mean square over 7ms intervals (MATLAB function ‘envelope’ with option ‘rms’). From all LFPs across tetrodes in the CA1 layer, the LFP whose power estimate had the highest standard deviation was then used to define ripple events, as 100ms windows around the peak power, whenever the power was greater than the 99th percentile of all powers in the trial (approximately equal to 4 standard deviations above the mean). Multi-unit activity (MUA) bursts were defined by binning all spikes from CS cells into 1ms bins and smoothing the resulting binned spike train with a Gaussian kernel (s.d. 10ms). MUA events were then defined as crossing of a threshold defined as 3 standard deviations above the mean of the smoothed spike train, with a duration from 100-750ms. Only MUA bursts which temporally overlapped (even in part) with SWR events were included in the replay analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18eb40dd-606f-45a3-88f2-d0c5687062c5",
   "metadata": {},
   "source": [
    "## **Open Sleep Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd89a50-b76a-4fa7-8ede-e9556e87ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_scheme.csv')\n",
    "sleep = df.loc[df.sleep == 1]\n",
    "sleep_files = df.loc[df.sleep == 1, ['folder', 'filename']].agg('/'.join, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49a9488-e989-4b65-af05-c886fdf0bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_files = [file for file in sleep_files if 'awake' not in file.split('_')]\n",
    "sleep_files = [file for file in sleep_files if 'awake.set' not in file.split('_')]\n",
    "filenames = [r.strip().split('/')[-1] for r in sleep_files]\n",
    "sleep = df[df.filename.isin(filenames)]\n",
    "sleep_files = sleep.loc[sleep.sleep == 1, ['folder', 'filename']].agg('/'.join, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a9f332-5aee-45a4-bb4a-9654828b8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sleep['rat'].value_counts().plot(kind='bar',\n",
    "                                    figsize=(9,5),\n",
    "                                    title=\"Number of sleep recordings for each animal.\")\n",
    "ax.set_xlabel(\"Rat ID\")\n",
    "ax.set_ylabel(\"Frequency of recordings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f0166-b61a-48cc-a167-86309a8527c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sleep['treatment'].value_counts().plot(kind='bar',\n",
    "                                    figsize=(9,5),\n",
    "                                    title=\"Treatment numberd in sleep animals.\")\n",
    "ax.set_xlabel(\"Treatment type\")\n",
    "ax.set_ylabel(\"Frequency of recordings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55cae64-ae08-4dab-b7eb-4dcf21f10b37",
   "metadata": {},
   "source": [
    "#### **Auxiliary functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb5fe9e-f1d7-48f8-8057-27411b3eff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_moving(file, tresh=2.5): # Mark timestamps were the speed > 2.5 cm/s\n",
    "    '''Mark movement > treshold on timestamps array (1 for movement, 0 for resting)\n",
    "    Inputs:\n",
    "        file(str): filename\n",
    "        tresh(float): treshold in cm/s\n",
    "    Returns:\n",
    "        moving(arr): 1 for movement, 0 for resting\n",
    "        \n",
    "    '''\n",
    "    pos = RecPos(file)\n",
    "    speed = pos.get_speed()\n",
    "    moving = np.zeros(len(speed)*5)\n",
    "    for i in range(0, len(speed)): \n",
    "        if speed[i] > tresh:\n",
    "            moving[5*i:5*i+5] = 1\n",
    "    return moving\n",
    "\n",
    "def resting_epochs(moving, epoch_size = 2): \n",
    "    ''' Define resting epochs on timestamps\n",
    "    Inputs:\n",
    "        moving(arr): treshold moving array\n",
    "        epoch_size(int): size of epochs in seconds\n",
    "    Returns:\n",
    "        rest_stamps(arr): File timestamps 0 non rest, 1 rest\n",
    "    '''\n",
    "    result = np.zeros(len(moving))\n",
    "    window = epoch_size * 250\n",
    "    for i in range(0, len(moving), window//2):\n",
    "        if sum(moving[i : i + window]) == 0 :\n",
    "            result[i : i + window] = 1\n",
    "    return result\n",
    "    \n",
    "def create_events(record, events):\n",
    "    '''Create events on MNE object\n",
    "    Inputs:\n",
    "        record(mne_object): recording to add events\n",
    "        events_time(2D np array): array 0,1 with same lenght of recording dimension (1, lengt(record))\n",
    "    output: \n",
    "    record(mne_object): Record with events added\n",
    "    '''\n",
    "    events = np.reshape(events, (1,-1))\n",
    "    try:\n",
    "        assert len(record.times) == events.shape[1]\n",
    "        stim_data = events\n",
    "        info = mne.create_info(['STI'], record.info['sfreq'], ['stim'])\n",
    "        stim_raw = mne.io.RawArray(stim_data, info)\n",
    "        record.add_channels([stim_raw], force_update_info=True)\n",
    "    except AssertionError as error:\n",
    "        print(error)\n",
    "        print('The lenght of events needs to be equal to record lenght.')\n",
    "    return record\n",
    "\n",
    "def bandpower(data, low, high, window_sec = 2, sf = 250, relative_power = True):\n",
    " \n",
    "    from scipy.signal import welch\n",
    "    from scipy.integrate import simps\n",
    "    scale = 1000 \n",
    "    lfp_samples = data * scale\n",
    "    _filter = [1.5, 40]\n",
    "\n",
    "    # Compute the modified periodogram (Welch)\n",
    "    nperseg = int(window_sec * sf)\n",
    "    freqs, psd = welch(lfp_samples, sf, nperseg=nperseg)\n",
    "\n",
    "    # Frequency resolution\n",
    "    freq_res = freqs[1] - freqs[0]\n",
    "\n",
    "    # Find index of band in frequency vector\n",
    "    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
    "\n",
    "    # Integral approximation of the spectrum using parabola (Simpson's\n",
    "    # rule)\n",
    "    bp = simps(psd[idx_band], dx=freq_res)\n",
    "\n",
    "    idx_band = np.logical_and(freqs >= _filter[0], freqs <= _filter[1])\n",
    "    tp = simps(psd[idx_band], dx=freq_res)\n",
    "\n",
    "    if relative_power:\n",
    "        return bp / tp\n",
    "    return bp\n",
    "\n",
    "\n",
    "def bandpower_ratio(data, win_sec=2):\n",
    "   \n",
    "    b1 = bandpower(data, 1., 4., win_sec)\n",
    "    b2 = bandpower(data, 5., 11., win_sec)\n",
    "    if b1 == b2:\n",
    "        print(\"Error!\")\n",
    "    bp = b1 / b2\n",
    "    return bp\n",
    "\n",
    "def resting_periods(file, speed_tresh = 2.5, win_sec=2): \n",
    "    ''' Define resting epochs on timestamps\n",
    "    Inputs:\n",
    "        file(str): file to be calculated\n",
    "        speed_tresh(float): minimum treshold speed\n",
    "        win_sec(int): window in seconds to be calculated periods\n",
    "    Returns:\n",
    "        file_resting(arr): File timestamps 0 non rest, 1 rest for each channel\n",
    "    '''\n",
    "    file_resting = []\n",
    "    moving = mark_moving(file, speed_tresh)\n",
    "    mne_file = mne_lfp_Axona(file)\n",
    "    for channel in tqdm(range(0, len(mne_file.info['ch_names']))):\n",
    "        data = mne_file.get_data()\n",
    "        result = np.zeros(len(moving))\n",
    "        window = win_sec * 250\n",
    "        for i in range(0, len(moving) - 250, window//2):\n",
    "            bp = bandpower_ratio(data[channel][i : i + window], win_sec)\n",
    "            if sum(moving[i : i + window]) == 0 and bp < 2:\n",
    "                result[i : i + window] = 1\n",
    "        file_resting.append(result)\n",
    "    return np.asarray(file_resting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a40090-4853-476b-b35e-471b20bd8cf2",
   "metadata": {},
   "source": [
    "#### **Plot time distribuition for filtered files times by movement and by movement and relative power**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c6374d-1647-43bd-b394-e4435518ed24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d375bdd7-55b3-4883-8e08-c456bc42f579",
   "metadata": {},
   "source": [
    "#### **Divide files into treatment groups**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdb27c1-5e8d-4efb-9d35-9c9bed8f894e",
   "metadata": {},
   "outputs": [],
   "source": [
    "musc = sleep.loc[sleep.treatment == 'muscimol']\n",
    "control = sleep.loc[sleep.treatment == 'Control']\n",
    "lesion = sleep.loc[sleep.treatment == 'lesion']\n",
    "print(f'Muscimol: {len(musc)} recordings in {len(musc.rat.unique())} animals')\n",
    "print(f'Control: {len(control)} recordings in {len(control.rat.unique())} animals')\n",
    "print(f'Lesion: {len(lesion)} recordings in {len(lesion.rat.unique())} animals')\n",
    "msc_files = musc.loc[musc.treatment == 'muscimol', ['folder', 'filename']].agg('/'.join, axis=1).values\n",
    "cnt_files = control.loc[control.treatment == 'muscimol', ['folder', 'filename']].agg('/'.join, axis=1).values\n",
    "les_files = lesion.loc[lesion.treatment == 'muscimol', ['folder', 'filename']].agg('/'.join, axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2868508-70d9-4c55-82aa-81d756a39eb3",
   "metadata": {},
   "source": [
    "### **Calculate spindles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f484567-f067-4766-a03f-023ffbd8b87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mne_lfp_Axona(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2172f86b-e952-4c27-b548-8aa1817e21b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_array = resting_periods(file, speed_tresh = 2.5, win_sec=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca298cb-4828-4663-8680-db273957103c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(f_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94779e68-3b17-456a-ad63-4598297be710",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(12, 4))\n",
    "plt.specgram(data[0:50000], NFFT=500, Fs=250., noverlap=250  ,cmap='jet_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8cba4-a15d-410c-a59b-97b70eb7f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = msc_files[0]\n",
    "data = mne_lfp_Axona(test_data)\n",
    "sp = yasa.spindles_detect(data, 250., ch_names=['ch_1'], thresh={'rel_pow': 0.2, 'corr': 0.65, 'rms': 2.5}, freq_sp= (12, 15), multi_only=True, verbose='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d8707-d3ae-4a17-8bb4-ee4fc43780d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ee31bd-808a-4d00-9fa4-1d16a30e3103",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch1 = df.loc[df.Channel == 'ch_1']\n",
    "ch2 = df.loc[df.Channel == 'ch_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2356cb2-f65a-4ed4-8d24-d657815389a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ch1 oscilations mean: {ch1.Oscillations.mean():.2f}, std: {ch1.Oscillations.std():.2f}')\n",
    "print(f'Ch2 oscilations mean: {ch2.Oscillations.mean():.2f}, std: {ch2.Oscillations.std():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae2a1e3-74d2-402d-82ed-10d10a0863ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch4 = df.loc[df.Channel == 'ch_4']\n",
    "ch5 = df.loc[df.Channel == 'ch_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd88289a-2dcb-4ff0-82b3-8c539192643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Ch4 oscilations mean: {ch4.Oscillations.mean():.2f}, std: {ch4.Oscillations.std():.2f}')\n",
    "print(f'Ch5 oscilations mean: {ch5.Oscillations.mean():.2f}, std: {ch5.Oscillations.std():.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef58d843-f2b8-4991-be53-303cb3744a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_spindles(files, channel_names = ['ch_1']):\n",
    "    ''''''\n",
    "    spindles_list = []\n",
    "    for file in files:\n",
    "        data = mne_lfp_Axona(file)\n",
    "        sp = yasa.spindles_detect(data, 250., ch_names=channel_names, thresh={'rel_pow': 0.2, 'corr': 0.65, 'rms': 2.5}, freq_sp= (12, 15), multi_only=True, verbose='error')\n",
    "        df = sp.summary()\n",
    "        df.loc[df.]\n",
    "        \n",
    "    return spindles_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a959a745-8ed8-4ee9-8816-91150ec8d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sps = process_spindles(msc_files, channel_names = ['ch_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0632294b-5dc6-4710-928e-45b9ab23a0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sps[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e8dbdf-1e76-434d-bc74-f11c7d2e0171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = mne_lfp_Axona(sleep_files[13])\n",
    "data = data.filter(l_freq=10, h_freq = 16,  method='fir',verbose=0).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daecd4b6-9462-4794-b2da-6b322bf1123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7529398e-924e-4f7c-90d3-6715396264ae",
   "metadata": {},
   "source": [
    "**Spindle Detection and Verification** [https://academic.oup.com/sleep/article/39/5/1069/2454043?login=true#125103895]\n",
    "\n",
    "We developed an algorithm to automatically detect sleep spindle events in line with previous studies.(20,39) LFP raw data was resampled to 1,000 Hz, band-pass filtered (using a zero-phase, second order, Infinite Impulse Response Butterworth filter) between 10–16 Hz and the instantaneous amplitude was extracted via the Hilbert transform. Then, two thresholds were set relatively to the mean band-pass signal during NREM sleep: (1) a “detection threshold” (+2 SD above the mean) identified events as potential spindles, and (2) a “noise threshold” (+0.2 SD above the mean) was used to define the start and end of sleep spindle event. To verify specificity for sleep spindles (versus broadband power increases), we excluded any putative spindle event whose instantaneous amplitude in a control frequency band (20–30 Hz) exceeded a predefined threshold of +4.5 SD above the mean. Finally an event qualified as a spindle if its duration was between 0.5 and 2.5 sec. It should be emphasized that the specific parameters of the spindle detection algorithm (e.g., frequency range, filter settings, thresholds) were optimized after extensive visual inspection to minimize false detections, and a wide range of parameters yielded similar detections and overall results (data not shown). Power spectral density (Figure 2B) was computed on 350-msec time windows centered on spindle peaks or random time-intervals in NREM sleep."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595a65cd-47d0-4dbd-b2c2-9eef90baa50f",
   "metadata": {},
   "source": [
    "#### **Calculate Welch's PSD**\n",
    "\n",
    "The gold-standard and most widely-used method to calculate the power spectral density (PSD) of EEG data is the Welch's sliding periodogram, which is implemented in SciPy.\n",
    "\n",
    "The Welch's method improves the accuracy of the classic periodogram. The reason is simple: EEG data are always time-varying, meaning that if you look at a 30 seconds of EEG data, it is very (very) unlikely that the signal will looks like a perfect sum of pure sines. Rather, the spectral content of the EEG changes over time, constantly modified by the neuronal activity at play under the scalp. Problem is, to return a true spectral estimate, a classic periodogram requires the spectral content of the signal to be stationnary (i.e. time-unvarying) over the time period considered. Because it is never the case, the periodogram is generally biased and contains way too much variance. By averaging the periodograms obtained over short segments of the windows, the Welch's method allows to drastically reduce this variance. This comes at the cost, however, of a lower frequency resolution. The frequency resolution in Welch's method is defined by the window length, such that $F = 1 / t$, with $t$ being the window length in seconds. In other words, a 4-sec sliding window will give a frequency resolution of 1 / 4 = 0.25 Hz.\n",
    "\n",
    "How do we define the optimal window duration then? A commonly used approach is to take a window sufficiently long to encompasses at least two full cycles of the lowest frequency of interest. So for instance, if our lowest frequency of interest is 1 Hz so we will choose a window of 2 / 1 = 2 seconds.\n",
    "\n",
    "Note that in the code below, I use a median average of all the resulting sliding windows. Indeed, this may result in less biased and more accurate PSD as explained in this "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
