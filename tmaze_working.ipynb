{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys  \n",
    "sys.path.insert(0, 'D:/Beths/')\n",
    "# sys.path.insert(0, 'D:/NeuroChaT/neurochat/')\n",
    "# from neurochat.nc_lfp import NLfp\n",
    "import os\n",
    "import re\n",
    "from mne.preprocessing import ICA\n",
    "import mne\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import statistics\n",
    "import math\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import matplotlib.cm as cm\n",
    "from shapely.geometry import Point, Polygon\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "## Import from my files\n",
    "from data_lfp import mne_lfp_Axona, load_lfp_Axona\n",
    "from data_pos import RecPos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Class to read position files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecPos:\n",
    "    \"\"\"\n",
    "    This data class contains information about the recording position.\n",
    "    Read .pos file\n",
    "    To dos:\n",
    "        * read different numbers of LEDs\n",
    "        * Adapt to NeuroChat\n",
    "    Attributes\n",
    "    ----------\n",
    "    _file_tag : str\n",
    "        The tag of the pos data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_name):\n",
    "\n",
    "        self.bytes_per_sample = 20  # Axona daqUSB manual\n",
    "        file_directory, file_basename = os.path.split(file_name)\n",
    "        file_tag, file_extension = os.path.splitext(file_basename)\n",
    "        file_extension = file_extension[1:]\n",
    "        self.pos_file = os.path.join(file_directory, file_tag + \".pos\")\n",
    "        if os.path.isfile(self.pos_file):\n",
    "            with open(self.pos_file, \"rb\") as f:\n",
    "                while True:\n",
    "                    line = f.readline()\n",
    "                    try:\n",
    "                        line = line.decode(\"latin-1\")\n",
    "                    except BaseException:\n",
    "                        break\n",
    "\n",
    "                    if line == \"\":\n",
    "                        break\n",
    "                    if line.startswith(\"trial_date\"):\n",
    "                        # Blank pos file\n",
    "                        if line.strip() == \"trial_date\":\n",
    "                            total_samples = 0\n",
    "                            print(\"No position data.\")\n",
    "                            return\n",
    "                        date = \" \".join(line.replace(\",\", \" \").split()[1:])\n",
    "                    if line.startswith(\"num_colours\"):\n",
    "                        colors = int(line.split()[1])\n",
    "                    if line.startswith(\"min_x\"):\n",
    "                        self.min_x = int(line.split()[1])\n",
    "                    if line.startswith(\"max_x\"):\n",
    "                        self.max_x = int(line.split()[1])\n",
    "                    if line.startswith(\"min_y\"):\n",
    "                        self.min_y = int(line.split()[1])\n",
    "                    if line.startswith(\"max_y\"):\n",
    "                        self.max_y = int(line.split()[1])\n",
    "                    if line.startswith(\"window_min_x\"):\n",
    "                        self.window_min_x = int(line.split()[1])\n",
    "                    if line.startswith(\"window_max_x\"):\n",
    "                        self.window_max_x = int(line.split()[1])\n",
    "                    if line.startswith(\"window_min_y\"):\n",
    "                        self.window_min_y = int(line.split()[1])\n",
    "                    if line.startswith(\"window_max_y\"):\n",
    "                        self.window_max_y = int(line.split()[1])\n",
    "                    if line.startswith(\"bytes_per_timestamp\"):\n",
    "                        self.bytes_per_tstamp = int(line.split()[1])\n",
    "                    if line.startswith(\"bytes_per_coord\"):\n",
    "                        self.bytes_per_coord = int(line.split()[1])\n",
    "                    if line.startswith(\"pixels_per_metre\"):\n",
    "                        self.pixels_per_metre = int(line.split()[1])\n",
    "                    if line.startswith(\"num_pos_samples\"):\n",
    "                        self.total_samples = int(line.split()[1])\n",
    "                    if line.startswith(\"data_start\"):\n",
    "                        break\n",
    "\n",
    "                f.seek(0, 0)\n",
    "                header_offset = []\n",
    "                while True:\n",
    "                    try:\n",
    "                        buff = f.read(10).decode(\"UTF-8\")\n",
    "                    except BaseException:\n",
    "                        break\n",
    "                    if buff == \"data_start\":\n",
    "                        header_offset = f.tell()\n",
    "                        break\n",
    "                    else:\n",
    "                        f.seek(-9, 1)\n",
    "\n",
    "                if not header_offset:\n",
    "                    print(\"Error: data_start marker not found!\")\n",
    "                else:\n",
    "                    f.seek(header_offset, 0)\n",
    "                    byte_buffer = np.fromfile(f, dtype=\"uint8\")\n",
    "                    len_bytebuffer = len(byte_buffer)\n",
    "                    end_offset = len(\"\\r\\ndata_end\\r\")\n",
    "                    num_samples = int(len((byte_buffer) - end_offset) / 20)\n",
    "                    big_spotx = np.zeros([self.total_samples, 1])\n",
    "                    big_spoty = np.zeros([self.total_samples, 1])\n",
    "                    little_spotx = np.zeros([self.total_samples, 1])\n",
    "                    little_spoty = np.zeros([self.total_samples, 1])\n",
    "                    self.time = np.zeros([self.total_samples, 1])\n",
    "                    # pos format: t,x1,y1,x2,y2,numpix1,numpix2 => 20 bytes\n",
    "                    for i, k in enumerate(\n",
    "                        np.arange(0, self.total_samples * 20, 20)\n",
    "                    ):  # Extract bytes from 20 bytes words\n",
    "                        byte_offset = k\n",
    "                        big_spotx[i] = int(\n",
    "                            256 * byte_buffer[k + 4] + byte_buffer[k + 5]\n",
    "                        )  # 4,5 bytes for big LED x\n",
    "                        big_spoty[i] = int(\n",
    "                            256 * byte_buffer[k + 6] + byte_buffer[k + 7]\n",
    "                        )  # 6,7 bytes for big LED x\n",
    "                        little_spotx[i] = int(\n",
    "                            256 * byte_buffer[k + 4] + byte_buffer[k + 5]\n",
    "                        )\n",
    "                        little_spoty[i] = int(\n",
    "                            256 * byte_buffer[k + 6] + byte_buffer[k + 7]\n",
    "                        )\n",
    "\n",
    "\n",
    "                    self.raw_position = {\n",
    "                        \"big_spotx\": big_spotx,\n",
    "                        \"big_spoty\": big_spoty,\n",
    "                        \"little_spotx\": little_spotx,\n",
    "                        \"little_spoty\": little_spoty,\n",
    "                    }\n",
    "\n",
    "        else:\n",
    "            print(f\"No pos file found for file {self.pos_file}\")\n",
    "\n",
    "    def get_cam_view(self):\n",
    "        self.cam_view = {\n",
    "            \"min_x\": self.min_x,\n",
    "            \"max_x\": self.max_x,\n",
    "            \"min_y\": self.min_y,\n",
    "            \"max_y\": self.max_y,\n",
    "        }\n",
    "        return self.cam_view\n",
    "\n",
    "    def get_tmaze_start(self):\n",
    "        x, y = self.get_position()\n",
    "        a = x[100:300]\n",
    "        b = y[100:300]\n",
    "        a = pd.Series([n if n != 1023 else np.nan for n in a])\n",
    "        b = pd.Series([n if n != 1023 else np.nan for n in b])\n",
    "        a.clip(0, 500, inplace=True)\n",
    "        b.clip(0, 500, inplace=True)\n",
    "        a.fillna(method=\"backfill\", inplace=True)\n",
    "        b.fillna(method=\"backfill\", inplace=True)\n",
    "        if a.median() < 200 and b.mean() > 300:\n",
    "            start = \"top left\"\n",
    "        elif a.median() > 400 and b.mean() > 300:\n",
    "            start = \"top right\"\n",
    "        elif a.median() < 200 and b.mean() < 200:\n",
    "            start = \"down left\"\n",
    "        elif a.median() > 300 and b.mean() < 200:\n",
    "            start = \"down right\"\n",
    "        else:\n",
    "            start = \"impossible to find\"\n",
    "        return start\n",
    "\n",
    "    def get_window_view(self):\n",
    "        try:\n",
    "            self.windows_view = {\n",
    "                \"window_min_x\": self.window_min_x,\n",
    "                \"window_max_x\": self.window_max_x,\n",
    "                \"window_min_y\": self.window_min_y,\n",
    "                \"window_max_y\": self.window_max_y,\n",
    "            }\n",
    "            return self.windows_view\n",
    "        except:\n",
    "            print(\"No window view\")\n",
    "\n",
    "    def get_pixel_per_metre(self):\n",
    "        return self.pixels_per_metre\n",
    "\n",
    "    def get_raw_pos(self):\n",
    "        bigx = [value[0] for value in self.raw_position[\"big_spotx\"]]\n",
    "        bigy = [value[0] for value in self.raw_position[\"big_spoty\"]]\n",
    "\n",
    "        return bigx, bigy\n",
    "\n",
    "    def filter_max_speed(self, x, y, max_speed = .6):  # max speed\n",
    "        tmp_x = x.copy()\n",
    "        tmp_y = y.copy()\n",
    "        for i in range(1, len(tmp_x) - 1):\n",
    "            if (math.sqrt((x[i] - x[i - 1]) ** 2 + (y[i] - y[i - 1]) ** 2)) > (\n",
    "                max_speed * self.pixels_per_metre\n",
    "            ):\n",
    "                tmp_x[i] = np.nan\n",
    "                tmp_y[i] = np.nan\n",
    "        return tmp_x, tmp_y\n",
    "\n",
    "    def get_position(self):\n",
    "        try:\n",
    "            count_missing = 0\n",
    "            bxx, sxx = [], []\n",
    "            byy, syy = [], []            \n",
    "            bigx = [value[0] for value in self.raw_position[\"big_spotx\"]]\n",
    "            bigy = [value[0] for value in self.raw_position[\"big_spoty\"]]\n",
    "            smallx = [value[0] for value in self.raw_position[\"little_spotx\"]]\n",
    "            smally = [value[0] for value in self.raw_position[\"little_spoty\"]]\n",
    "            for bx, sx in zip(bigx, smallx):  # Try to clean single blocked LED x\n",
    "                if bx == 1023 and sx != 1023:\n",
    "                    bx = sx\n",
    "                elif bx != 1023 and sx == 1023:\n",
    "                    sx = bx\n",
    "                elif bx == 1023 and sx == 1023:\n",
    "                    count_missing += 1\n",
    "                    bx = np.nan\n",
    "                    sx = np.nan\n",
    "\n",
    "                bxx.append(bx)\n",
    "                sxx.append(sx)\n",
    "\n",
    "            for by, sy in zip(bigy, smally):  # Try to clean single blocked LED y\n",
    "                if by == 1023 and sy != 1023:\n",
    "                    by = sy\n",
    "                elif by != 1023 and sy == 1023:\n",
    "                    sy = by\n",
    "                elif by == 1023 and sy == 1023:\n",
    "                    by = np.nan\n",
    "                    sy = np.nan\n",
    "                byy.append(by)\n",
    "                syy.append(sy)\n",
    "\n",
    "            ### Remove coordinates with max_speed \n",
    "            bxx, byy = self.filter_max_speed(bxx, byy)\n",
    "            sxx, syy = self.filter_max_speed(sxx, syy)\n",
    "\n",
    "            ### Interpolate missing values\n",
    "            bxx = (pd.Series(bxx).astype(float)).interpolate(\"cubic\")\n",
    "            sxx = (pd.Series(sxx).astype(float)).interpolate(\"cubic\")\n",
    "            byy = (pd.Series(byy).astype(float)).interpolate(\"cubic\")\n",
    "            syy = (pd.Series(syy).astype(float)).interpolate(\"cubic\")\n",
    "            \n",
    "            ### Average both LEDs\n",
    "            x = list((bxx + sxx) / 2)\n",
    "            y = list((byy + syy) / 2)\n",
    "            \n",
    "            \n",
    "            ## Boxcar filter 400 ms (axona tint default)\n",
    "            # sample rate = 20 ms\n",
    "            b = int(400 / 20)\n",
    "            kernel = np.ones(b) / b\n",
    "\n",
    "            def pad_and_convolve(xx, kernel):\n",
    "                npad = len(kernel)\n",
    "                xx = np.pad(xx, (npad, npad), \"edge\")\n",
    "                yy = np.convolve(xx, kernel, mode=\"same\")\n",
    "                return yy[npad:-npad]\n",
    "\n",
    "            x = pad_and_convolve(x, kernel)\n",
    "            y = pad_and_convolve(y, kernel)\n",
    "            \n",
    "            # Remove the last np.nans\n",
    "            x = [vx for vx in x if vx != np.nan]\n",
    "            y = [vy for vy in y if vy != np.nan]\n",
    "            \n",
    "            return x, y\n",
    "        except:\n",
    "            print(f\"No position information found in {self.pos_file}\")\n",
    "\n",
    "    def get_speed(self):\n",
    "        print(\"Not implemented\")\n",
    "        pass\n",
    "\n",
    "    def get_angular_pos(self):\n",
    "        print(\"Not implemented\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Function that reads LFP from the entire file and convert to MNE format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function from NeuroChat - read LFP\n",
    "def load_lfp_Axona(file_name):\n",
    "\n",
    "    file_directory, file_basename = os.path.split(file_name)\n",
    "    file_tag, file_extension = os.path.splitext(file_basename)\n",
    "    file_extension = file_extension[1:]\n",
    "    set_file = os.path.join(file_directory, file_tag + \".set\")\n",
    "    if os.path.isfile(file_name):\n",
    "        with open(file_name, \"rb\") as f:\n",
    "            while True:\n",
    "                line = f.readline()\n",
    "                try:\n",
    "                    line = line.decode(\"latin-1\")\n",
    "                except BaseException:\n",
    "                    break\n",
    "\n",
    "                if line == \"\":\n",
    "                    break\n",
    "                if line.startswith(\"trial_date\"):\n",
    "                    # Blank eeg file\n",
    "                    if line.strip() == \"trial_date\":\n",
    "                        total_samples = 0\n",
    "                        return\n",
    "                    date = \" \".join(line.replace(\",\", \" \").split()[1:])\n",
    "                if line.startswith(\"trial_time\"):\n",
    "                    time = line.split()[1]\n",
    "                if line.startswith(\"experimenter\"):\n",
    "                    experimenter = \" \".join(line.split()[1:])\n",
    "                if line.startswith(\"comments\"):\n",
    "                    comments = \" \".join(line.split()[1:])\n",
    "                if line.startswith(\"duration\"):\n",
    "                    duration = float(\"\".join(line.split()[1:]))\n",
    "                if line.startswith(\"sw_version\"):\n",
    "                    file_version = line.split()[1]\n",
    "                if line.startswith(\"num_chans\"):\n",
    "                    total_channel = int(\"\".join(line.split()[1:]))\n",
    "                if line.startswith(\"sample_rate\"):\n",
    "                    sampling_rate = float(\"\".join(re.findall(r\"\\d+.\\d+|\\d+\", line)))\n",
    "                if line.startswith(\"bytes_per_sample\"):\n",
    "                    bytes_per_sample = int(\"\".join(line.split()[1:]))\n",
    "                if line.startswith(\"num_\" + file_extension[:3].upper() + \"_samples\"):\n",
    "                    total_samples = int(\"\".join(line.split()[1:]))\n",
    "                if line.startswith(\"data_start\"):\n",
    "                    break\n",
    "\n",
    "            num_samples = total_samples\n",
    "            f.seek(0, 0)\n",
    "            header_offset = []\n",
    "            while True:\n",
    "                try:\n",
    "                    buff = f.read(10).decode(\"UTF-8\")\n",
    "                except BaseException:\n",
    "                    break\n",
    "                if buff == \"data_start\":\n",
    "                    header_offset = f.tell()\n",
    "                    break\n",
    "                else:\n",
    "                    f.seek(-9, 1)\n",
    "\n",
    "            eeg_ID = re.findall(r\"\\d+\", file_extension)\n",
    "            file_tag = 1 if not eeg_ID else int(eeg_ID[0])\n",
    "            max_ADC_count = 2 ** (8 * bytes_per_sample - 1) - 1\n",
    "            max_byte_value = 2 ** (8 * bytes_per_sample)\n",
    "\n",
    "            with open(set_file, \"r\", encoding=\"latin-1\") as f_set:\n",
    "                lines = f_set.readlines()\n",
    "                channel_lines = dict(\n",
    "                    [\n",
    "                        tuple(map(int, re.findall(r\"\\d+.\\d+|\\d+\", line)[0].split()))\n",
    "                        for line in lines\n",
    "                        if line.startswith(\"EEG_ch_\")\n",
    "                    ]\n",
    "                )\n",
    "                channel_id = channel_lines[file_tag]\n",
    "                channel_id = channel_id\n",
    "\n",
    "                gain_lines = dict(\n",
    "                    [\n",
    "                        tuple(map(int, re.findall(r\"\\d+.\\d+|\\d+\", line)[0].split()))\n",
    "                        for line in lines\n",
    "                        if \"gain_ch_\" in line\n",
    "                    ]\n",
    "                )\n",
    "                gain = gain_lines[channel_id - 1]\n",
    "\n",
    "                for line in lines:\n",
    "                    if line.startswith(\"ADC_fullscale_mv\"):\n",
    "                        fullscale_mv = int(re.findall(r\"\\d+.\\d+|d+\", line)[0])\n",
    "                        break\n",
    "                AD_bit_uvolt = (\n",
    "                    2 * fullscale_mv / (gain * np.power(2, 8 * bytes_per_sample))\n",
    "                )\n",
    "\n",
    "            record_size = bytes_per_sample\n",
    "            sample_le = 256 ** (np.arange(0, bytes_per_sample, 1))\n",
    "\n",
    "            if not header_offset:\n",
    "                print(\"Error: data_start marker not found!\")\n",
    "            else:\n",
    "                f.seek(header_offset, 0)\n",
    "                byte_buffer = np.fromfile(f, dtype=\"uint8\")\n",
    "                len_bytebuffer = len(byte_buffer)\n",
    "                end_offset = len(\"\\r\\ndata_end\\r\")\n",
    "                lfp_wave = np.zeros(\n",
    "                    [\n",
    "                        num_samples,\n",
    "                    ],\n",
    "                    dtype=np.float64,\n",
    "                )\n",
    "                for k in np.arange(0, bytes_per_sample, 1):\n",
    "                    byte_offset = k\n",
    "                    sample_value = (\n",
    "                        sample_le[k]\n",
    "                        * byte_buffer[\n",
    "                            byte_offset : byte_offset\n",
    "                            + len_bytebuffer\n",
    "                            - end_offset\n",
    "                            - record_size : record_size\n",
    "                        ]\n",
    "                    )\n",
    "                    if sample_value.size < num_samples:\n",
    "                        sample_value = np.append(\n",
    "                            sample_value,\n",
    "                            np.zeros(\n",
    "                                [\n",
    "                                    num_samples - sample_value.size,\n",
    "                                ]\n",
    "                            ),\n",
    "                        )\n",
    "                    sample_value = sample_value.astype(\n",
    "                        np.float64, casting=\"unsafe\", copy=False\n",
    "                    )\n",
    "                    np.add(lfp_wave, sample_value, out=lfp_wave)\n",
    "                np.putmask(\n",
    "                    lfp_wave, lfp_wave > max_ADC_count, lfp_wave - max_byte_value\n",
    "                )\n",
    "\n",
    "                samples = lfp_wave * AD_bit_uvolt\n",
    "                # timestamp = (\n",
    "                #     np.arange(0, num_samples, 1) / sampling_rate)\n",
    "                return samples\n",
    "\n",
    "    else:\n",
    "        print(\"No lfp file found for file {}\".format(file_name))\n",
    "\n",
    "\n",
    "def mne_lfp_Axona(file_name):\n",
    "    \"\"\"\n",
    "    Create a mne object from a Axona recording.\n",
    "    ------\n",
    "    Load all channels from an Axona recording into a mne object\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "    ------\n",
    "    file_name (str): Axona .set file in the same folder as the EEG recordings referents to the set file\n",
    "\n",
    "    Returns:\n",
    "    ------\n",
    "    MNE object with N channels named as ch_0 - ch_N\n",
    "\n",
    "    \"\"\"\n",
    "    file_directory, file_basename = os.path.split(file_name)\n",
    "    file_tag, file_extension = os.path.splitext(file_basename)\n",
    "    set_file = os.path.join(file_directory, file_tag + \".set\")\n",
    "\n",
    "    # Open Set files configurations\n",
    "    with open(file_name, \"r\", encoding=\"latin-1\") as f_set:\n",
    "        lines = f_set.readlines()\n",
    "        for line in lines:\n",
    "            if line.startswith(\"ADC_fullscale_mv\"):\n",
    "                fullscale_mv = int(re.findall(r\"\\d+.\\d+|d+\", line)[0])\n",
    "        channel_map = dict(  # map internal channels from Axona set\n",
    "            [\n",
    "                tuple(map(int, re.findall(r\"\\d+.\\d+|\\d+\", line)[0].split()))\n",
    "                for line in lines\n",
    "                if line.startswith(\"EEG_ch_\")\n",
    "            ]\n",
    "        )\n",
    "        recorded_channels = dict(  # map or recorded channels from Axona set\n",
    "            [\n",
    "                tuple(map(int, re.findall(r\"\\d+.\\d+|\\d+\", line)[0].split()))\n",
    "                for line in lines\n",
    "                if line.startswith(\"saveEEG_ch_\")\n",
    "            ]\n",
    "        )\n",
    "        channel_ids = [\n",
    "            ch for ch in recorded_channels.keys() if recorded_channels[ch]\n",
    "        ]  # All recorded EEG channels\n",
    "        gains = [\n",
    "            int((re.findall(r\"\\d+.\\d+|\\d+\", line)[0].split()[1]))\n",
    "            for line in lines\n",
    "            if \"gain_ch_\" in line\n",
    "        ]  # List of gains\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "    ch_types = []\n",
    "    for ch in channel_ids:  # Loop for all channels\n",
    "        if ch == 1:\n",
    "            eeg_file = (\n",
    "                file_directory + \"/\" + file_tag + \".eeg\"\n",
    "            )  # if it is the first eeg channel\n",
    "        else:\n",
    "            eeg_file = file_directory + \"/\" + file_tag + \".eeg\" + str(ch)\n",
    "\n",
    "        if os.path.isfile(eeg_file):  # open eeg file\n",
    "            with open(eeg_file, \"rb\") as f:\n",
    "                while True:\n",
    "                    line = f.readline()\n",
    "                    try:\n",
    "                        line = line.decode(\"latin-1\")\n",
    "                    except:\n",
    "                        try:\n",
    "                            line = line.decode(\"UTF-8\")\n",
    "                        except BaseException:\n",
    "                            break\n",
    "                    if line == \"\":\n",
    "                        break\n",
    "                    if line.startswith(\"trial_date\"):\n",
    "                        # Blank eeg file\n",
    "                        if line.strip() == \"trial_date\":\n",
    "                            total_samples = 0\n",
    "                            break\n",
    "                        date = \" \".join(line.replace(\",\", \" \").split()[1:])\n",
    "                    if line.startswith(\"trial_time\"):\n",
    "                        time = line.split()[1]\n",
    "                    if line.startswith(\"experimenter\"):\n",
    "                        experimenter = \" \".join(line.split()[1:])\n",
    "                    if line.startswith(\"comments\"):\n",
    "                        comments = \" \".join(line.split()[1:])\n",
    "                    if line.startswith(\"duration\"):\n",
    "                        duration = float(\"\".join(line.split()[1:]))\n",
    "                    if line.startswith(\"sw_version\"):\n",
    "                        file_version = line.split()[1]\n",
    "                    if line.startswith(\"num_chans\"):\n",
    "                        total_channel = int(\"\".join(line.split()[1:]))\n",
    "                    if line.startswith(\"sample_rate\"):\n",
    "                        sampling_rate = float(\"\".join(re.findall(r\"\\d+.\\d+|\\d+\", line)))\n",
    "                    if line.startswith(\"bytes_per_sample\"):\n",
    "                        bytes_per_sample = int(\"\".join(line.split()[1:]))\n",
    "                    if line.startswith(\"num_EEG_samples\"):\n",
    "                        total_samples = int(\"\".join(line.split()[1:]))\n",
    "                    if line.startswith(\"data_start\"):\n",
    "                        break\n",
    "\n",
    "                f.seek(0, 0)\n",
    "                header_offset = []\n",
    "                while True:\n",
    "                    try:\n",
    "                        buff = f.read(10).decode(\"UTF-8\")\n",
    "                    except BaseException:\n",
    "                        break\n",
    "                    if buff == \"data_start\":\n",
    "                        header_offset = f.tell()\n",
    "                        break\n",
    "                    else:\n",
    "                        f.seek(-9, 1)\n",
    "                if not header_offset:\n",
    "                    print(\"Error: data_start marker not found!\")\n",
    "                else:\n",
    "                    AD_bit_uvolt = (\n",
    "                        2\n",
    "                        * fullscale_mv\n",
    "                        / (\n",
    "                            gains[channel_map[ch] - 1]\n",
    "                            * np.power(2, 8 * bytes_per_sample)\n",
    "                        )\n",
    "                    )\n",
    "                    num_samples = total_samples\n",
    "                    max_ADC_count = 2 ** (8 * bytes_per_sample - 1) - 1\n",
    "                    max_byte_value = 2 ** (8 * bytes_per_sample)\n",
    "                    record_size = bytes_per_sample\n",
    "                    sample_le = 256 ** (np.arange(0, bytes_per_sample, 1))\n",
    "                    f.seek(header_offset, 0)\n",
    "                    byte_buffer = np.fromfile(f, dtype=\"uint8\")\n",
    "                    len_bytebuffer = len(byte_buffer)\n",
    "                    end_offset = len(\"\\r\\ndata_end\\r\")\n",
    "                    lfp_wave = np.zeros(\n",
    "                        [\n",
    "                            num_samples,\n",
    "                        ],\n",
    "                        dtype=np.float64,\n",
    "                    )\n",
    "                    for k in np.arange(0, bytes_per_sample, 1):\n",
    "                        byte_offset = k\n",
    "                        sample_value = (\n",
    "                            sample_le[k]\n",
    "                            * byte_buffer[\n",
    "                                byte_offset : byte_offset\n",
    "                                + len_bytebuffer\n",
    "                                - end_offset\n",
    "                                - record_size : record_size\n",
    "                            ]\n",
    "                        )\n",
    "                        if sample_value.size < num_samples:\n",
    "                            sample_value = np.append(\n",
    "                                sample_value,\n",
    "                                np.zeros(\n",
    "                                    [\n",
    "                                        num_samples - sample_value.size,\n",
    "                                    ]\n",
    "                                ),\n",
    "                            )\n",
    "                        sample_value = sample_value.astype(\n",
    "                            np.float64, casting=\"unsafe\", copy=False\n",
    "                        )\n",
    "                        np.add(lfp_wave, sample_value, out=lfp_wave)\n",
    "                    np.putmask(\n",
    "                        lfp_wave, lfp_wave > max_ADC_count, lfp_wave - max_byte_value\n",
    "                    )\n",
    "                    samples = lfp_wave * AD_bit_uvolt\n",
    "\n",
    "                    timestamp = np.arange(0, num_samples, 1) / sampling_rate\n",
    "                    lfp_data = lfp_wave * AD_bit_uvolt\n",
    "                    if max(lfp_data) > 0:\n",
    "                        data.append((lfp_wave * AD_bit_uvolt) / 1000)\n",
    "                        labels.append(f\"ch_{ch}\")\n",
    "                        ch_types.append(\"eeg\")\n",
    "    \n",
    "    info = mne.create_info(ch_names=labels, sfreq=sampling_rate, ch_types=ch_types)\n",
    "    return mne.io.RawArray(np.array(data), info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Plot helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_small_sq(x,y, wview):\n",
    "    ax = plt.figure(figsize=(3,3))\n",
    "    ax = plt.axis('off')\n",
    "    ax = plt.scatter(x, y , c=\"black\",marker='.')\n",
    "    ax = plt.xlim(40, 300)#xmax=int(wview['window_max_x']))\n",
    "    ax = plt.ylim(40, 300)#ymax=int(wview['window_max_y']))\n",
    "#     ax = plt.plot(x,y, c= 'g')\n",
    "    ax = plt.xlabel('X pixels')\n",
    "    ax = plt.ylabel('Y pixels')\n",
    "#     ax = plt.title('T maze postition plot')\n",
    "    plt.tight_layout()\n",
    "    return plt.show()\n",
    "\n",
    "def plot_tmaze(x,y, wview, dot = True):\n",
    "    ax = plt.figure(figsize=(6,6))\n",
    "#     ax = plt.axis('off')\n",
    "    if dot:\n",
    "        ax = plt.scatter(x, y , c=\"black\",marker='.')\n",
    "    else:\n",
    "        ax = plt.plot(x,y, c= 'g', linewidth=3)\n",
    "    ax = plt.xlim(0, xmax=int(wview['window_max_x']))\n",
    "    ax = plt.ylim(0, ymax=int(wview['window_max_y']))\n",
    "    ax = plt.xlabel('X pixels')\n",
    "    ax = plt.ylabel('Y pixels')\n",
    "   \n",
    "    ax = plt.title('T maze postition plot')\n",
    "    plt.tight_layout()\n",
    "    return plt.show()\n",
    "\n",
    "def plot_mne(raw_array, base_name):\n",
    "    raw_array.load_data()\n",
    "    raw_array.plot(\n",
    "        n_channels=2,\n",
    "        block=True,\n",
    "        duration=30,\n",
    "        show=True,\n",
    "        clipping=\"transparent\",\n",
    "        title=\"Raw LFP Data from {}\".format(base_name),\n",
    "        remove_dc=False,\n",
    "        scalings=dict(eeg=250e-5),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Read data table and select Tmaze recordings**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_scheme.csv', parse_dates=['date_time'] )\n",
    "df = df.loc[df.maze != 'screening']\n",
    "df = df.loc[df.habituation == 0]\n",
    "tmaze_files = df.loc[df.maze == 'tmaze', ['folder', 'filename']].agg('/'.join, axis=1).values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Open LFP data in MNE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0,len(tmaze_files))\n",
    "file = tmaze_files[i]\n",
    "lfps = mne_lfp_Axona(file)\n",
    "pos = RecPos(file)\n",
    "plot_mne(lfps, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the start, for each position sample (50hz), 5 EEGs samples are collected. \n",
    "**Cut all nan values from the x,y and keep the smaller continuous (x or y) trunked by nans**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in tmaze_files:\n",
    "#     try:\n",
    "#         pos = RecPos(file)\n",
    "#         x,y = pos.get_position()\n",
    "#         rx,ry = pos.get_raw_pos()\n",
    "#         nanX =  sum([a for a in x if a == np.nan])\n",
    "#         nanY = sum([a for a in y if a == np.nan])\n",
    "#         if nanX >0:\n",
    "#             print(f' x: {nanX}\\t y: {nanY}')\n",
    "#     except:\n",
    "#          continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Finding decision region**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "\n",
    "1. get the order of the points\n",
    "\n",
    "2. find where the animal turned to left or right\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find the turn:**\n",
    "   1. define a vector lenght (ex. 100)\n",
    "   2. walk with this vector from the middle of the start arm to the end\n",
    "   3. divide this vector into 2 with a gap in the middle (ex. a: 40 gap:20 b:40)\n",
    "   4. Normalize both small vectors\n",
    "   5. calculate the direction with dot product\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = {\n",
    "    'down left': [(225,110),(290,175),(180,235),(100, 140)],\n",
    "    'top left':  [(100,250),(205,390),(300,340),(180,200)],\n",
    "    'top right':[(370,235),(260,310),(360, 400),(460,330)],\n",
    "    'down right':  [(365,100),(465,160),(375,230),(290,160)],\n",
    "    'impossible to find': [(0,1),(2,1),(2, 2),(2,2)]\n",
    "     }\n",
    "\n",
    "def is_inside(x, y, start):\n",
    "    points_inside = []\n",
    "    coord = {\n",
    "        'down left': [(225,110),(290,175),(180,235),(100, 140)],\n",
    "        'top left':  [(100,250),(205,390),(300,340),(180,200)],\n",
    "        'top right':[(370,235),(260,310),(360, 400),(460,330)],\n",
    "        'down right':  [(365,100),(465,160),(375,230),(290,160)],\n",
    "        'impossible to find': [(0,1),(2,1),(2, 2),(2,2)]\n",
    "     }\n",
    "    region = Polygon(coord[start])\n",
    "    for vx,vy in zip(x,y):\n",
    "        p = Point(vx,vy)\n",
    "        if p.within(region):\n",
    "            points_inside.append((vx,vy))\n",
    "    if len(points_inside) > 0:\n",
    "        return points_inside\n",
    "    else: \n",
    "        return False\n",
    "\n",
    "def move_window(x, y, idx, size, space):\n",
    "    '''break the vextor into 2 divided by a space in the middle'''\n",
    "    bx = x[idx : idx + size]\n",
    "    by = y[idx : idx + size]\n",
    "    cx = x[idx + size + space : idx + 2*size + space]\n",
    "    cy = y[idx + size + space : idx + 2*size + space]\n",
    "    return bx, by, cx, xy\n",
    "\n",
    "def calculate_regression(x, y):\n",
    "    '''Calculate linear regression and return the new line'''\n",
    "    regr = linear_model.LinearRegression()\n",
    "    x = np.array(x).reshape(-1,1)    \n",
    "    y = np.array(y)\n",
    "    regr.fit(x, y)\n",
    "    y_pred = regr.predict(x)\n",
    "    return x, y_pred\n",
    " \n",
    "def calculate_angle(a, b, c):\n",
    "    ang = math.degrees(math.atan2(c[1]-b[1], c[0]-b[0]) - math.atan2(a[1]-b[1], a[0]-b[0]))\n",
    "    return ang + 360 if ang < 0 else ang\n",
    "\n",
    "def calculate_lenght(a, b):\n",
    "    return math.sqrt(((a[-1] - a[0])**2) + ((b[-1] - b[0])**2))\n",
    "\n",
    "\n",
    "def is_out(x_med, y_med, px, py, d):\n",
    "    ''' Cheks if a point is far from the (x_mean, y_mean) point\n",
    "    Given a point (px,py) and the mean of start, the function\n",
    "    return True of False if the point is outside a defined \n",
    "    distance\n",
    "    \n",
    "    input: (float): x_mean, y_mean, px, py\n",
    "    output: (bool):\n",
    "    '''\n",
    "    return  d > math.sqrt((px-x_med)**2 + (py-y_med)**2)\n",
    "        \n",
    "    \n",
    "def get_cord_inside(x,y,start):\n",
    "    '''check if points are inside the determined \n",
    "    region based on start'''\n",
    "    \n",
    "    insiders = is_inside(x,y,start)\n",
    "    area = coord[start]\n",
    "    aera_x = [b[0] for b in area]\n",
    "    area_y = [b[1] for b in area]\n",
    "    if pos.get_tmaze_start() in coord.keys():\n",
    "        c = coord[pos.get_tmaze_start()]\n",
    "    px = [b[0] for b in insiders]\n",
    "    py = [b[1] for b in insiders]\n",
    "    return px,py\n",
    "\n",
    "\n",
    "# def filter_high_density_point(x,y):\n",
    "    \n",
    "#     read = {}\n",
    "#     points = [(xn,yn) for xn,yn in zip(x,y)]\n",
    "#     count_dict = {i:points.count(i) for i in points}\n",
    "#     for k in count_dict.keys():\n",
    "#         if count_dict[k]\n",
    "    \n",
    "#     return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/mnt/d/Beths/CSR6/+ maze/27032018_t3/S8/27032018_CSR6_+maze_t3_.set'\n",
    "x,y = pos.get_position()\n",
    "\n",
    "start = pos.get_tmaze_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Test Sean idea of getting values outside a range from the beggining**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_start_points(file):\n",
    "    pos = RecPos(file)\n",
    "    x,y = pos.get_position()\n",
    "    start = pos.get_tmaze_start()\n",
    "    wview = pos.get_window_view()\n",
    "    #remove nans\n",
    "    x = np.asarray(x)[~np.isnan(x)]\n",
    "    y = np.asarray(y)[~np.isnan(y)]\n",
    "    ax = plt.figure(figsize=(6,6))\n",
    "    ax = plt.plot(x,y, c='black', linewidth=.4)\n",
    "    x_med = np.median(x[300:500])\n",
    "    y_med = np.median(y[300:500])\n",
    "    outs = 0\n",
    "    st = 200\n",
    "    idx = st\n",
    "    outx = []\n",
    "    outy= []\n",
    "    d = 90\n",
    "    for px, py in list(zip(x,y))[st:]:\n",
    "        idx+=1\n",
    "        if math.sqrt((px-x_med)**2 + (py-y_med)**2) >= d:\n",
    "            outs+=1\n",
    "            outx.append(px)\n",
    "            outy.append(py)\n",
    "            if outs > 30:\n",
    "                break\n",
    "        else:\n",
    "            outs = 0\n",
    "            outx = []\n",
    "            outy= [] \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/mnt/d/Beths/CSR6/+ maze/27032018_t3/S8/27032018_CSR6_+maze_t3_.set'\n",
    "pos = RecPos(file)\n",
    "x,y = pos.get_position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 30):\n",
    "    i = random.randint(0,len(tmaze_files))\n",
    "    file = tmaze_files[i]\n",
    "    pos = RecPos(file)\n",
    "    x,y = pos.get_position()\n",
    "    start = pos.get_tmaze_start()\n",
    "    wview = pos.get_window_view()\n",
    "    #remove nans\n",
    "    x = np.asarray(x)[~np.isnan(x)]\n",
    "    y = np.asarray(y)[~np.isnan(y)]\n",
    "    ax = plt.figure(figsize=(6,6))\n",
    "    ax = plt.plot(x,y, c='black', linewidth=.4)\n",
    "    x_med = np.median(x[300:500])\n",
    "    y_med = np.median(y[300:500])\n",
    "    st = 200\n",
    "    idx = st\n",
    "    outx = []\n",
    "    outy= []\n",
    "    d = 90\n",
    "    for px, py in list(zip(x,y))[st:]:\n",
    "        idx+=1\n",
    "        if math.sqrt((px-x_med)**2 + (py-y_med)**2) >= d:\n",
    "            outx.append(px)\n",
    "            outy.append(py)\n",
    "            if len(outx) > 90:\n",
    "                break\n",
    "        else:\n",
    "            outs = 0\n",
    "            outx = []\n",
    "            outy= [] \n",
    "            \n",
    "    x_med = np.median(x[100:300])\n",
    "    y_med = np.median(y[100:300])\n",
    "    x = x[st:idx+100]\n",
    "    y = y[st:idx+100]\n",
    "    ax = plt.plot(x,y, c='black', linewidth=1)\n",
    "    ax = plt.plot(outx,outy, c='green', linewidth=2)\n",
    "    ax = plt.xlim(0, xmax=int(wview['window_max_x']))\n",
    "    ax = plt.ylim(0, ymax=int(wview['window_max_y']))\n",
    "    ax = plt.scatter(x_med, y_med , c=\"red\",s = d**2, alpha =.1)\n",
    "    ax = plt.xlabel('X pixels')\n",
    "    ax = plt.ylabel('Y pixels')\n",
    "    ax = plt.title(f'{start}')\n",
    "    print(idx)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_dots(x,y):\n",
    "    x_med = np.median(x[300:500])\n",
    "    y_med = np.median(y[300:500])\n",
    "    outs = 0\n",
    "    st = 200\n",
    "    outx = []\n",
    "    outy= []\n",
    "    d = 30\n",
    "    for px, py in list(zip(x,y))[st:]:\n",
    "        if math.sqrt((px-x_med)**2 + (py-y_med)**2) >= d:\n",
    "            outs+=1\n",
    "            outx.append(px)\n",
    "            outy.append(py)\n",
    "            if outs > 30:\n",
    "                return outx, outy\n",
    "        else:\n",
    "            outs = 0\n",
    "            outx = []\n",
    "            outy= [] \n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Find before and after decision using regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/mnt/d/Beths/CSR6/+ maze/27032018_t3/S8/27032018_CSR6_+maze_t3_.set'\n",
    "pos = RecPos(file)\n",
    "x,y = pos.get_position()\n",
    "# get_first_dots(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0,10):\n",
    "    try:\n",
    "        i = random.randint(0,len(tmaze_files))\n",
    "        file = tmaze_files[i]\n",
    "        pos = RecPos(file)\n",
    "        x,y = pos.get_position()\n",
    "        x = np.asarray(x)[~np.isnan(x)]\n",
    "        y = np.asarray(y)[~np.isnan(y)]\n",
    "        x = x[:len(x)//2] # half of the recording\n",
    "        y = y[:len(y)//2] # half of the recording\n",
    "        start = pos.get_tmaze_start()\n",
    "        wview = pos.get_window_view()\n",
    "        space = 25 # space between regression lines\n",
    "        lenght = 90 # kength of regression line\n",
    "        idx = find_start_points(file)\n",
    "        print(idx)\n",
    "        for idx1 in range(idx, len(x)-2*lenght-space, 2):\n",
    "            idx2 = idx1+space+lenght\n",
    "            x1, y1 = calculate_regression(x[idx1:lenght+idx1], y[idx1:lenght+idx1])\n",
    "            lx1 = len(x1)//2\n",
    "            ly1 = len(y1)//2\n",
    "            x2,y2 = calculate_regression(x[idx2:lenght+idx2], y[idx2:lenght+idx2])\n",
    "            angle = calculate_angle((x1[0], y1[0]), (x1[-1], y1[-1]), (x2[-1],y2[-1]))\n",
    "            length1 = calculate_lenght(x[idx1:lenght+idx1],y[idx1:lenght+idx1])\n",
    "            length2 = calculate_lenght(x[idx2:lenght+idx2], y[idx2:lenght+idx2])\n",
    "            if angle > 65 and angle < 115  and length1 > 110 and length2 > 110 and is_inside(x1[lx1:lx1+1], y1[ly1:ly1+1], start):\n",
    "                print(angle)\n",
    "                ax = plt.figure(figsize=(5,5))\n",
    "                ax = plt.plot(x, y,  color='black', linewidth = .4) # plot maze\n",
    "                ax = plt.plot(x1, y1, color='red')\n",
    "                ax = plt.scatter(x[idx1:lenght+idx1], y[idx1:lenght+idx1], color='green')\n",
    "                ax = plt.plot(x2, y2, color='red')\n",
    "                ax = plt.scatter(x[idx2:lenght+idx2], y[idx2:lenght+idx2], color='blue')\n",
    "                ax = plt.axis('off')\n",
    "                ax = plt.xlim(0, xmax=int(wview['window_max_x']))\n",
    "                ax = plt.ylim(0, ymax=int(wview['window_max_y']))\n",
    "                ax = plt.xlabel('X pixels')\n",
    "                ax = plt.ylabel('Y pixels')\n",
    "                ax = plt.title('T maze postition plot')\n",
    "                plt.tight_layout()\n",
    "    #             plt.savefig('reg_tmaze6.png')\n",
    "                plt.show()\n",
    "                break\n",
    "    except:\n",
    "        print(file)\n",
    "        print(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a random T maze "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(0,len(tmaze_files))\n",
    "# file = '/mnt/d/Beths/LSubRet1/recording/+maze/06092017_3rd/S7/06092017_LSubRet1_+maze_trial_3_7.set'\n",
    "ax = plt.figure(figsize=(6,6))\n",
    "# for i in (range(0,1)):\n",
    "#     try:\n",
    "file = tmaze_files[i]\n",
    "pos = RecPos(file)\n",
    "x,y = pos.get_position()\n",
    "x = x[:len(x)//2]\n",
    "y = y[:len(y)//2]\n",
    "start = pos.get_tmaze_start()\n",
    "insiders = is_inside(x,y,start)\n",
    "area = coord[start]\n",
    "aera_x = [b[0] for b in area]\n",
    "area_y = [b[1] for b in area]\n",
    "if pos.get_tmaze_start() in coord.keys():\n",
    "    c = coord[pos.get_tmaze_start()]\n",
    "px = [b[0] for b in insiders]\n",
    "py = [b[1] for b in insiders]\n",
    "wview = pos.get_window_view()\n",
    "ax = plt.scatter(x, y , c=\"black\",marker='.',  alpha=0.5)\n",
    "ax = plt.plot(aera_x, area_y , c=\"red\",marker='.')\n",
    "ax = plt.axis('on')\n",
    "ax = plt.scatter(px, py, c=\"green\",marker='_')\n",
    "ax = plt.xlim(0, xmax=int(wview['window_max_x']))\n",
    "ax = plt.ylim(0, ymax=int(wview['window_max_y']))\n",
    "ax = plt.xlabel(file)\n",
    "ax = plt.ylabel('Y pixels')\n",
    "ax = plt.title(f'Started { pos.get_tmaze_start()}')\n",
    "\n",
    "#     except:\n",
    "#         continue\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'decision_point_{i}.png')\n",
    "# # plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_bbox():\n",
    "    \n",
    "\n",
    "# def get_tmaze_start(x,y):\n",
    "\n",
    "#     a = x[100:250]\n",
    "#     b = y[100:250]\n",
    "#     a = pd.Series([n if n != 1023 else np.nan for n in a])\n",
    "#     b = pd.Series([n if n != 1023 else np.nan for n in b])\n",
    "#     a.clip(0, 500, inplace=True)\n",
    "#     b.clip(0, 500, inplace=True)\n",
    "#     a.fillna(method=\"backfill\", inplace=True)\n",
    "#     b.fillna(method=\"backfill\", inplace=True)\n",
    "#     if a.mean() < 200 and b.mean() > 300:\n",
    "#         start = \"top left\"\n",
    "#     elif a.mean() > 400 and b.mean() > 300:\n",
    "#         start = \"top right\"\n",
    "#     elif a.mean() < 200 and b.mean() < 200:\n",
    "#         start = \"down left\"\n",
    "#     elif a.mean() > 300 and b.mean() < 200:\n",
    "#         start = \"down right\"\n",
    "#     else:\n",
    "#         start = \"impossible to find\"\n",
    "#     return start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Separate into forced and choice**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(\"T_maze LFP\", figsize=(8,8))\n",
    "\n",
    "# Plot the T maze position\n",
    "pos = RecPos(file)\n",
    "print(pos.pos_file)\n",
    "x,y = pos.get_position()\n",
    "pos.get_tmaze_start()\n",
    "wview = pos.get_window_view()\n",
    "ax0 = fig.add_subplot(2, 2, 1)\n",
    "ax0 = plt.plot(x,y, c= 'black', linewidth=2, alpha=.3)\n",
    "ax0 = plt.scatter(x[0:len(x)//2], y[0:len(x)//2] , c=\"black\",marker='.')\n",
    "ax0 = plt.xlim(0, xmax=int(wview['window_max_x']))\n",
    "ax0 = plt.ylim(0, ymax=int(wview['window_max_y']))\n",
    "ax0 = plt.xlabel('X pixels')\n",
    "ax0 = plt.ylabel('Y pixels')\n",
    "ax0 = plt.title(f'Forced path started on {pos.get_tmaze_start()}')\n",
    "plt.tight_layout()\n",
    "\n",
    "ax0 = fig.add_subplot(2, 2, 2)\n",
    "ax0 = plt.scatter(x[len(x)//2:], y[len(x)//2:], c=\"black\",marker='.')\n",
    "ax0 = plt.plot(x,y, c= 'black', linewidth=2, alpha=.3)\n",
    "ax0 = plt.xlim(0, xmax=int(wview['window_max_x']))\n",
    "ax0 = plt.ylim(0, ymax=int(wview['window_max_y']))\n",
    "ax0 = plt.xlabel('X pixels')\n",
    "ax0 = plt.ylabel('Y pixels')\n",
    "ax0 = plt.title(f'Choosen path started on {pos.get_tmaze_start()}')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Load the EEG data\n",
    "ch0_f =  load_lfp_Axona(file[:-3] + 'eeg')\n",
    "half = int(len(ch0_f)/2)\n",
    "ch1_f = load_lfp_Axona(file[:-3] + 'eeg2')\n",
    "ch0_c = load_lfp_Axona(file[:-3] + 'eeg3')\n",
    "ch1_c = load_lfp_Axona(file[:-3] + 'eeg4')\n",
    "eeg = [ch0_f[0:half], ch1_f[0:half], ch0_c[half:], ch1_c[half:] ]\n",
    "\n",
    "data = np. array(eeg)\n",
    "data = data.T\n",
    "n_samples = len(load_lfp_Axona(file[:-3]+'eeg')[0:half])\n",
    "n_rows = len(eeg)\n",
    "t = 10 * np.arange(n_samples) / n_samples\n",
    "\n",
    "# Plot the EEG\n",
    "ticklocs = []\n",
    "ax2 = fig.add_subplot(2, 1, 2)\n",
    "ax2.set_xlim(0, 10)\n",
    "ax2.set_xticks(np.arange(10))\n",
    "dmin = data.min()\n",
    "dmax = data.max()\n",
    "dr = (dmax - dmin) * 2  # Crowd them a bit.\n",
    "y0 = dmin\n",
    "y1 = (n_rows - 1) * dr + dmax\n",
    "ax2.set_ylim(y0, y1)\n",
    "segs = []\n",
    "for i in range(n_rows):\n",
    "    segs.append(np.column_stack((t, data[:, i])))\n",
    "    ticklocs.append(i * dr)\n",
    "offsets = np.zeros((n_rows, 2), dtype=float)\n",
    "offsets[:, 1] = ticklocs\n",
    "lines = LineCollection(segs, offsets=offsets, transOffset=None)\n",
    "ax2.add_collection(lines)\n",
    "\n",
    "# Set the yticks to use axes coordinates on the y axis\n",
    "ax2.set_yticks(ticklocs)\n",
    "ax2.set_yticklabels(['ch0 forced', 'ch1 forced', 'ch0 choice', 'ch1 choice'])\n",
    "ax2.set_xlabel('Time (s)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('Tmaze3.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try plotting a bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_in_circle_np(radius, x0=0, y0=0, ):\n",
    "    x_ = np.arange(x0 - radius - 1, x0 + radius + 1, dtype=int)\n",
    "    y_ = np.arange(y0 - radius - 1, y0 + radius + 1, dtype=int)\n",
    "    x, y = np.where((x_[:,np.newaxis] - x0)**2 + (y_ - y0)**2 <= radius**2)\n",
    "#     x, y = np.where((np.hypot((x_-x0)[:,np.newaxis], y_-y0)<= radius)) # alternative implementation\n",
    "    for x, y in zip(x_[x], y_[y]):\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0,2):\n",
    "    i = random.randint(0,len(tmaze_files))\n",
    "    file = tmaze_files[i]\n",
    "    pos = RecPos(file)\n",
    "    x,y = pos.get_position()\n",
    "    #remove nans\n",
    "    x = np.asarray(x)[~np.isnan(x)]\n",
    "    y = np.asarray(y)[~np.isnan(y)]\n",
    "    start = pos.get_tmaze_start()\n",
    "    ax = plt.figure(figsize=(6,6))\n",
    "    circle = plt.Circle((0,0), radius= 5)\n",
    "    ax = plt.plot(x,y, c= 'black', linewidth=1, alpha = .7)\n",
    "    ax = plt.xlim(0, xmax=int(wview['window_max_x']))\n",
    "    ax = plt.ylim(0, ymax=int(wview['window_max_y']))\n",
    "    x_avg = np.median(x)\n",
    "    y_avg = np.median(y)\n",
    "    ax = plt.scatter(x_avg, y_avg , c=\"red\",s=3000)\n",
    "    ax = plt.xlabel('X pixels')\n",
    "    ax = plt.ylabel('Y pixels')\n",
    "    ax = plt.title(f'{start}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
